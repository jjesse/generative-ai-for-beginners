# Exploring and comparing different LLMs

## Understand different types of LLMs

LLMs can have multiple categorizations based on their architecture, training data, and use cases and here are some examples:

- Audio and speech recognition
  - Whisper type models are a great choice
  - Trained on diverse audio and can perform multilingual speech recognition
- Image generation
  - DALL-E and Midjourney are two very known choices
- Text generation
  - Most models are trained on text generation and there is a wide variety of choices
 
## Foundation models versus LLMs

Standford researchers coined the term and defined it as an AI Model that:

- Trained using unsupervised learning or self-supervised learning
  - They were trained on unlabled multi-model data
  - Do not require human annotation or labeling of data for their training process
- They are very large models
  - Baed on very deep neural networks trained on billions of parameters
- They are intended to serve as a foundation for other models
  - Can be used a starting point for other models to be built on
 
## Open Source versus Proprietary Models
